STEP 1:
pip install streamlit pandas numpy plotly ibm-watson-machine-learning¬†python-dotenv


STEP 2:
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
import os
# Set your Hugging Face token securely
os.environ['HF_TOKEN'] = "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"
model_id = "ibm-granite/granite-3.3-2b-instruct"
# Load tokenizer and model using your token
tokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token=os.getenv('HF_TOKEN'))
model = AutoModelForCausalLM.from_pretrained(model_id, use_auth_token=os.getenv('HF_TOKEN'))
# Create a pipeline for text generation
generator = pipeline("text-generation", model=model, tokenizer=tokenizer, device_map="auto", max_new_tokens=512)


STEP 3:
def medical_qa(query):
    prompt = f"Q: {query}\nA:"
    response = generator(prompt)[0]["generated_text"]
    return response.split("A:")[-1].strip()

def symptom_checker(symptoms):
    prompt = f"A patient has symptoms: {symptoms}. What are possible conditions?"
    return generator(prompt)[0]["generated_text"]

def report_summarizer(report_text):
    prompt = f"Summarize this medical report in simple language:\n{report_text}"
    return generator(prompt)[0]["generated_text"]

def medication_info(medicine):
    prompt = f"What is {medicine}? Include usage, dosage, and side effects."
    return generator(prompt)[0]["generated_text"]

def lifestyle_suggestion(condition):
    prompt = f"Give lifestyle and diet advice for someone with {condition}."
    return generator(prompt)[0]["generated_text"]

def mental_health_chat(message):
    prompt = f"You are a friendly and supportive mental health assistant. Respond to: {message}"
    return generator(prompt)[0]["generated_text"]

def doctor_finder(issue):
    prompt = f"What type of doctor should someone consult for: {issue}?"
    return generator(prompt)[0]["generated_text"]

def health_tip(topic):
    prompt = f"Give a health tip about: {topic}"
    return generator(prompt)[0]["generated_text"]


STEP 4:
import gradio as gr

with gr.Blocks() as demo:
    gr.Markdown("# üß† HealthAI - Intelligent Healthcare Assistant")

    with gr.Tab("ü©∫ Medical Q&A"):
        q = gr.Textbox(label="Ask a Medical Question")
        a = gr.Textbox(label="Answer")
        btn = gr.Button("Submit")
        btn.click(medical_qa, inputs=q, outputs=a)

    with gr.Tab("üßæ Symptom Checker"):
        s = gr.Textbox(label="Enter your symptoms")
        result = gr.Textbox(label="Possible conditions")
        gr.Button("Check").click(symptom_checker, inputs=s, outputs=result)

    with gr.Tab("üìÑ Health Report Summarizer"):
        report_input = gr.Textbox(label="Paste medical report")
        summary = gr.Textbox(label="Simplified Summary")
        gr.Button("Summarize").click(report_summarizer, inputs=report_input, outputs=summary)

    with gr.Tab("üíä Medication Advisor"):
        med = gr.Textbox(label="Enter medicine name")
        medinfo = gr.Textbox(label="Medication Info")
        gr.Button("Get Info").click(medication_info, inputs=med, outputs=medinfo)

    with gr.Tab("ü•ó Lifestyle & Diet Advice"):
        cond = gr.Textbox(label="Health condition (e.g., diabetes)")
        advice = gr.Textbox(label="Advice")
        gr.Button("Suggest").click(lifestyle_suggestion, inputs=cond, outputs=advice)

    with gr.Tab("üßò Mental Health Chat"):
        mh_msg = gr.Textbox(label="Say something...")
        mh_reply = gr.Textbox(label="Support Response")
        gr.Button("Talk").click(mental_health_chat, inputs=mh_msg, outputs=mh_reply)

    with gr.Tab("üë®‚Äç‚öï Doctor Finder"):
        issue = gr.Textbox(label="Describe your issue")
        doc_sugg = gr.Textbox(label="Suggested Specialist")
        gr.Button("Find").click(doctor_finder, inputs=issue, outputs=doc_sugg)

    with gr.Tab("üí° Health Tip Generator"):
        tip_input = gr.Textbox(label="Ask for a health tip on...")
        tip_output = gr.Textbox(label="Health Tip")
        gr.Button("Generate Tip").click(health_tip, inputs=tip_input, outputs=tip_output)

demo.launch()